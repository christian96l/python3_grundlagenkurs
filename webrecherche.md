
# Herunterladen von Webseiten

**üéØ Lade Daten von einer dynamischen Webseite oder einem RSS-Feed herunter.**

### Aufgabe 1

Suche Dir eine der folgenden Seiten aus:

| Seite | Link |
|-------|------|
| RSS-Feeds des Parlaments | [https://www.parlament-berlin.de/de/Service/RSS-Feeds](https://www.parlament-berlin.de/de/Service/RSS-Feeds) |
| Presse | [http://www.reuters.com/tools/rss](http://www.reuters.com/tools/rss) |
| Biologische Datenbanken (NCBI Esearch) | [https://www.ncbi.nlm.nih.gov/books/NBK25499/](https://www.ncbi.nlm.nih.gov/books/NBK25499/) |

### Aufgabe 2

Lade eine Seite/den Feed mit Python herunter. Entscheide was f√ºr Daten Du extrahieren m√∂chtest.

### Aufgabe 3

Inspiziere den Quelltext. Suche nach markanten Elementen, anhand derer Du Titel, Links oder Inhalte erkennst.

### Aufgabe 4

Entwickle eine Strategie zum Extrahieren der Daten. Verwende die Methoden von Strings, regul√§re Ausdr√ºcke oder einen fertigen Parser.

### Aufgabe 5

Lade 10 Teilergebnisse herunter und gib sie aus.


## N√ºtzliche Module

* `requests` zum Herunterladen von Webseiten
* `BeautifulSoup` zum Parsen von HTML-Seiten
* `scrapy` f√ºr beides zusammen
